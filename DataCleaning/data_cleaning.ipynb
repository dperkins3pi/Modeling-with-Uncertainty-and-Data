{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Essentials: Data Cleaning\n",
    "    Daniel Perkins\n",
    "    MATH 403\n",
    "    10/15/24\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "The g\\_t\\_results.csv file is a set of parent-reported scores on their child's Gifted and Talented tests. \n",
    "The two tests, OLSAT and NNAT, are used by NYC to determine if children are qualified for gifted programs.\n",
    "The OLSAT Verbal has 16 questions for Kindergardeners and 30 questions for first, second, and third graders.\n",
    "The NNAT has 48 questions. Each test assigns 1 point to each question asked (so there are no non integer scores).\n",
    "Using this dataset, answer the following questions.\n",
    "\n",
    "\n",
    "\n",
    "1) What column has the highest number of null values and what percent of its values are null? Print the answer as a tuple with (column name, percentage). Make sure the second value is a percent.\n",
    "\n",
    "2) List the columns that should be numeric that aren't. Print the answer as a tuple.\n",
    "\n",
    "3) How many third graders have scores outside the valid range for the OLSAT Verbal Score? Print the answer\n",
    "\n",
    "4) How many data values are missing (NaN)? Print the number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column with the most null values is:\n",
      "('School Assigned', 0.7521367521367521)\n"
     ]
    }
   ],
   "source": [
    "# 1) What column has the highest number of null values and what percent of its values are null? \n",
    "# Print the answer as a tuple with (column name, percentage). \n",
    "# Make sure the second value is a percent.\n",
    "\n",
    "results = pd.read_csv(\"g_t_results.csv\")  # Load in data\n",
    "null_percents = results.isna().mean()  # Count missing values (as a mean)\n",
    "answer = (null_percents.idxmax(), max(null_percents))\n",
    "print(\"The column with the most null values is:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp                      object\n",
      "Entering Grade Level           object\n",
      "District                      float64\n",
      "Birth Month                    object\n",
      "OLSAT Verbal Score             object\n",
      "OLSAT Verbal Percentile        object\n",
      "NNAT Non Verbal Raw Score      object\n",
      "NNAT Non Verbal Percentile      int64\n",
      "Overall Score                   int64\n",
      "School Preferences             object\n",
      "School Assigned                object\n",
      "Will you enroll there?         object\n",
      "dtype: object\n",
      "\n",
      "The columns that should be numeric but aren't are\n",
      "('OLSAT Verbal Score', 'OLSAT Verbal Percentile', 'NNAT Non Verbal Raw Score')\n"
     ]
    }
   ],
   "source": [
    "# 2) List the columns that should be numeric that aren't. Print the answer as a tuple.\n",
    "\n",
    "print(results.dtypes)  # Print out the data types\n",
    "print()\n",
    "wrong_type = (\"OLSAT Verbal Score\", \"OLSAT Verbal Percentile\", \"NNAT Non Verbal Raw Score\")\n",
    "\n",
    "print(\"The columns that should be numeric but aren't are\")\n",
    "print(wrong_type)\n",
    "# It may also be beneficial to make Timestamp, Grade Level, and Birth Month numeric (since they are ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 third grader(s) had OLSAT Verbal Scores that were out of the valid range\n"
     ]
    }
   ],
   "source": [
    "# 3) How many third graders have scores outside the valid range for the \n",
    "# OLSAT Verbal Score? Print the answer\n",
    "\n",
    "# results[\"Entering Grade Level\"].value_counts()\n",
    "third_graders = results[results[\"Entering Grade Level\"] == \"3\"]  # Just get third graders\n",
    "    \n",
    "scores_out_range = 0\n",
    "for index, row in third_graders.iterrows():  # Iterate through the rows\n",
    "    score = int(row[\"OLSAT Verbal Score\"])\n",
    "    if score < 0 or score > 30:  # If not in the valid range, add 1\n",
    "        scores_out_range += 1\n",
    "        \n",
    "print(f\"{scores_out_range} third grader(s) had OLSAT Verbal Scores that were out of the valid range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 values are missing from the data in total\n"
     ]
    }
   ],
   "source": [
    "# 4) How many data values are missing (NaN)? Print the number.\n",
    "null_count = results.isna().sum()  # Count missing values of each column\n",
    "null_count = null_count.sum()  # Add numbers from each column together\n",
    "print(f\"{null_count} values are missing from the data in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "imdb.csv contains a small set of information about 99 movies. Clean the data set by doing the following in order: \n",
    "\n",
    "1) Remove duplicate rows by dropping the first **or** last. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "2) Drop all rows that contain missing data. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "3) Remove rows that have data outside valid data ranges and explain briefly how you determined your ranges for each column.\n",
    "\n",
    "4) Identify and drop columns with three or fewer different values. Print a tuple with the names of the columns dropped.\n",
    "\n",
    "5) Convert the titles to all lower case.\n",
    "\n",
    "Print the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Data Cleaning: (99, 13)\n",
      "After removing duplicates: (93, 13)\n",
      "After removing missing data: (64, 13)\n",
      "After removing data outside of range: (55, 13)\n",
      "Dropped the columns: ('color', 'language')\n",
      "\n",
      "First Five Rows\n",
      "       director_name  duration        gross  \\\n",
      "0    Martin Scorsese       240  116866727.0   \n",
      "1        Shane Black       195  408992272.0   \n",
      "2  Quentin Tarantino       187   54116191.0   \n",
      "4      Peter Jackson       186  258355354.0   \n",
      "8        Joss Whedon       173  623279547.0   \n",
      "\n",
      "                                 genres                          movie_title  \\\n",
      "0          Biography|Comedy|Crime|Drama              the wolf of wall street   \n",
      "1               Action|Adventure|Sci-Fi                           iron man 3   \n",
      "2  Crime|Drama|Mystery|Thriller|Western                    the hateful eight   \n",
      "4                     Adventure|Fantasy  the hobbit: the desolation of smaug   \n",
      "8               Action|Adventure|Sci-Fi                         the avengers   \n",
      "\n",
      "   title_year country       budget  imdb_score  \\\n",
      "0        2013     USA  100000000.0         8.2   \n",
      "1        2013     USA  200000000.0         7.2   \n",
      "2        2015     USA   44000000.0         7.9   \n",
      "4        2013     USA  225000000.0         7.9   \n",
      "8        2012     USA  220000000.0         8.1   \n",
      "\n",
      "                                              actors  movie_facebook_likes  \n",
      "0  Leonardo DiCaprio,Matthew McConaughey,Jon Favreau                138000  \n",
      "1          Robert Downey Jr.,Jon Favreau,Don Cheadle                 95000  \n",
      "2          Craig Stark,Jennifer Jason Leigh,ZoÃ« Bell                114000  \n",
      "4              Aidan Turner,Adam Brown,James Nesbitt                 83000  \n",
      "8  Chris Hemsworth,Robert Downey Jr.,Scarlett Joh...                123000  \n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv(\"imdb.csv\")  # Load in data\n",
    "print(f\"Before Data Cleaning: {movies.shape}\")\n",
    "\n",
    "movies = movies.drop_duplicates(keep=\"first\")\n",
    "print(f\"After removing duplicates: {movies.shape}\")\n",
    "\n",
    "movies = movies.dropna()\n",
    "print(f\"After removing missing data: {movies.shape}\")\n",
    "\n",
    "# I determined which values to remove by calling min and max until it made sense for each category\n",
    "movies = movies[movies['duration'] >= 30] # Movies less than 30 minutes or more aren't really movies\n",
    "movies = movies[movies['duration'] <= 500]\n",
    "movies = movies[movies['gross'] >= 100000] # Some movies made way less than the rest\n",
    "movies = movies[movies['title_year'] >= 2000]  # Movies before this are not in the dataset\n",
    "movies = movies[movies['imdb_score'] >= 0]  # Movies can't have negative scores\n",
    "movies = movies[movies['movie_facebook_likes'] >= 1000]  # Movies should have at least a few lies\n",
    "print(f\"After removing data outside of range: {movies.shape}\")\n",
    "\n",
    "# Remove columns with less 3 or less unique values\n",
    "columns_to_remove = tuple(movies.columns[movies.nunique() <= 3])\n",
    "movies = movies.loc[:, movies.nunique() > 3]\n",
    "print(f\"Dropped the columns: {columns_to_remove}\")\n",
    "\n",
    "# Make the titles lower case\n",
    "movies[\"movie_title\"] = movies[\"movie_title\"].str.lower()\n",
    "\n",
    "# Print the first five rows\n",
    "print()\n",
    "print(\"First Five Rows\")\n",
    "print(movies[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Load housing.csv into a dataframe with index=0. Descriptions of the features are in housing_data_description.txt for your convenience.  \n",
    "The goal is to construct a regression model that predicts SalePrice using the other features of the dataset.  Do this as follows:\n",
    "\n",
    "\t1) Identify and handle the missing data.  Hint: Dropping every row with some missing data is not a good choice because it gives you an empty dataframe.  What can you do instead?\n",
    "    \n",
    "    2) Add two new features: \n",
    "\t\ta) Remodeled: Whether or not a house has been remodeled with a Y if it has been\n",
    "\t\t   remodeled, or a N if it has not.\n",
    "\t\t\n",
    "\t\tb) TotalPorch: Using the 5 different porch/deck columns, create a new column that\n",
    "\t\t   provides the total square footage of all the decks and porches for each house.\n",
    "    \n",
    "\t3) Identify the variable with nonnumeric values that are misencoded as numbers.  One-hot encode it. Hint: don't forget to remove one of the encoded columns to prevent collinearity with the constant column (which you will add later).\n",
    "    \n",
    "    4) Add a constant column to the dataframe.\n",
    "\n",
    "    5) Save a copy of the dataframe.\n",
    "\n",
    "\t6) Choose four categorical featrues that seem very important in predicting SalePrice. One-hot encode these features and remove all other categorical features.\n",
    "\t\t\n",
    "\t7) Run an OLS using all numerical data regression on your model.  \n",
    "\n",
    "\t\n",
    "Print the ten features that have the highest coef in your model. Then print the summary. Don't print the OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Using the copy of the dataframe you created in Problem 3, one-hot encode all the categorical variables.\n",
    "Print the shape of the dataframe and run OLS.\n",
    "\n",
    "Print the ten features that have the highest coef in your model and the summary.\n",
    "Write a couple of sentences discussing which model is better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".acme-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
